import sys
from pathlib import Path
import json
from datetime import datetime
import pandas as pd
import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT))

# ì ˆëŒ€ ì„í¬íŠ¸ ì‚¬ìš©
from chapters.ch31.craftsmen_data import CraftsmenDataGenerator
from chapters.ch31.vectorization_optimizer import VectorizationOptimizer
from chapters.ch31.eval_query_accelerator import EvalQueryAccelerator
from chapters.ch31.dtype_tuner import DtypeTuner

def print_chapter_header():
    """ì±•í„° í—¤ë” ì¶œë ¥"""
    header = (
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n"
        "â•‘                    JesusBornd Pandas Edition                         â•‘\n"
        "â•‘                                                                      â•‘\n"
        "â•‘             Chapter 31: ë¸Œì‚´ë ê³¼ ì˜¤í™€ë¦¬ì•• - ì„±ëŠ¥ ìµœì í™”                â•‘\n"
        "â•‘                                                                      â•‘\n"
        "â•‘    \"ëª¨ì„¸ê°€ ê·¸ ì¥ì¸ì˜ ë§ì„ ë“£ê³  ê·¸ ë§ëŒ€ë¡œ í•˜ì—¬\" (ì¶œì• êµ½ê¸° 31:1-11)\n"
        "â•‘    \"ë‚´ ì•„ë²„ì§€ê»˜ì„œ ì´ì œê¹Œì§€ ì¼í•˜ì‹œë‹ˆ ë‚˜ë„ ì¼í•œë‹¤\" (ìš”í•œë³µìŒ 5:17)\n"
        "â•‘                                                                      â•‘\n"
        "â•‘      ì¶œì• êµ½ê¸° 31ì¥: ë¸Œì‚´ë ê³¼ ì˜¤í™€ë¦¬ì••ì˜ ì§€í˜œì™€ ê¸°ìˆ                     â•‘\n"
        "â•‘      ìš”í•œë³µìŒ 5:17: ì˜ˆìˆ˜ë‹˜ì˜ ì¼í•˜ì‹¬ê³¼ í•˜ë‚˜ë‹˜ì˜ íš¨ìœ¨ì„±                  â•‘\n"
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    print(header)

def run_craftsmen_data_generation():
    """ì¥ì¸ ë°ì´í„° ìƒì„± ì„¹ì…˜ ì‹¤í–‰"""
    print("\nğŸ› ï¸ === ì¥ì¸ ë°ì´í„° ìƒì„± ===")
    print("ì„±ëŠ¥ ìµœì í™”ì— ì‚¬ìš©ë  ì„±ë§‰ ê±´ì¶• ì¥ì¸ ê´€ë ¨ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    print("Generates Tabernacle craftsmen data for performance optimization.")

    try:
        generator = CraftsmenDataGenerator()
        data = generator.generate_craftsmen_data()
        print("\nâœ… ì¥ì¸ ë°ì´í„° ìƒì„± ì™„ë£Œ:")
        print(data.head())
        return data
    except Exception as e:
        print(f"âŒ ì¥ì¸ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def run_vectorization_optimization(df):
    """ë²¡í„°í™” ì—°ì‚° ìµœì í™” ì„¹ì…˜ ì‹¤í–‰"""
    print("\nâš¡ === ë²¡í„°í™” ì—°ì‚° ìµœì í™” ===")
    print("ë²¡í„°í™” ì—°ì‚°ì„ í†µí•´ ëŒ€ê·œëª¨ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.")
    print("Optimizes performance by efficiently processing large datasets through vectorized operations.")

    if df is None:
        print("âš ï¸ ë°ì´í„°ê°€ ì—†ì–´ ë²¡í„°í™” ì—°ì‚° ìµœì í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None

    try:
        optimizer = VectorizationOptimizer(df)
        optimized_df = optimizer.calculate_total_time_vectorized()
        print("\nâœ… ë²¡í„°í™” ì—°ì‚° ìµœì í™” ì ìš© ì™„ë£Œ (ì¼ë¶€):")
        print(optimized_df.head())
        return optimized_df
    except Exception as e:
        print(f"âŒ ë²¡í„°í™” ì—°ì‚° ìµœì í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def run_eval_query_acceleration(df):
    """eval()/query() ê°€ì† ì„¹ì…˜ ì‹¤í–‰"""
    print("\nğŸš€ === eval()/query() ê°€ì† ===")
    print("`eval()` ë° `query()`ë¥¼ ì´ìš©í•˜ì—¬ ë³µì¡í•œ ì¡°ê±´ë¶€ ê³„ì‚°ì´ë‚˜ í•„í„°ë§ì„ ë¹ ë¥´ê²Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    print("Accelerates complex conditional calculations or filtering using `eval()` and `query()`.")

    if df is None:
        print("âš ï¸ ë°ì´í„°ê°€ ì—†ì–´ eval()/query() ê°€ì†ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None

    try:
        accelerator = EvalQueryAccelerator(df)
        eval_result = accelerator.apply_eval("total_time_minutes > 100 and material_cost > 500")
        query_result = accelerator.apply_query("craftsman == 'Bezalel' and total_time_minutes > 150")
        print("\nâœ… eval()/query() ê°€ì† ì ìš© ì™„ë£Œ (ì¼ë¶€):")
        print(eval_result.head())
        print(query_result.head())
        return {'eval_result': eval_result, 'query_result': query_result}
    except Exception as e:
        print(f"âŒ eval()/query() ê°€ì† ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def run_dtype_tuning(df):
    """ë°ì´í„° íƒ€ì… ìµœì í™” ì„¹ì…˜ ì‹¤í–‰"""
    print("\nğŸ’¾ === ë°ì´í„° íƒ€ì… ìµœì í™” ===")
    print("ë°ì´í„° íƒ€ì…(`dtype`) íŠœë‹ì„ í†µí•´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì´ê³  ë°ì´í„° ì²˜ë¦¬ ì†ë„ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.")
    print("Optimizes memory usage and data processing speed through `dtype` tuning.")

    if df is None:
        print("âš ï¸ ë°ì´í„°ê°€ ì—†ì–´ ë°ì´í„° íƒ€ì… ìµœì í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None

    try:
        tuner = DtypeTuner(df)
        optimized_df = tuner.optimize_dtypes()
        print("\nâœ… ë°ì´í„° íƒ€ì… ìµœì í™” ì ìš© ì™„ë£Œ (ì¼ë¶€):")
        print(optimized_df.head())
        return optimized_df
    except Exception as e:
        print(f"âŒ ë°ì´í„° íƒ€ì… ìµœì í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def show_blending_insights(original_df, optimized_df, eval_query_results, dtype_optimized_df):
    """ë¸”ë Œë”© ëª¨ë“œ í†µí•© í†µì°° ì¶œë ¥"""
    print("\nğŸ¨ === ë¸”ë Œë”© ëª¨ë“œ: ì¶œì• êµ½ Ã— ìš”í•œë³µìŒì˜ í†µí•© í†µì°° ===")
    print("Blending Mode: Integrated Insights from Exodus x John")

    blending_insights = [
        "ğŸ“Š ì„±ëŠ¥ ìµœì í™” = í•˜ë‚˜ë‹˜ì˜ ì¼í•˜ì‹¬ì˜ íš¨ìœ¨ì„±ê³¼ ëª©ì ì„±",
        "ğŸ› ï¸ ë¸Œì‚´ë ê³¼ ì˜¤í™€ë¦¬ì•• = ìµœê³ ì˜ ê¸°ìˆ ê³¼ ì§€í˜œë¡œ í•˜ë‚˜ë‹˜ì˜ ëª…ë ¹ ìˆ˜í–‰",
        "âœï¸ ì˜ˆìˆ˜ë‹˜ì˜ ì¼í•˜ì‹¬ = ì‰¬ì§€ ì•Šê³  íš¨ìœ¨ì ìœ¼ë¡œ ì¼í•˜ì‹œëŠ” í•˜ë‚˜ë‹˜ì˜ ë³¸ì„±",
        "ğŸ’¡ ìì› íš¨ìœ¨ì„± = ì˜ì  ì ˆì œì™€ ì§€í˜œë¡œìš´ ìì› ê´€ë¦¬"
    ]

    print("\nğŸ’ í•µì‹¬ ë°œê²¬ë“¤ (Key Discoveries):\n")
    for insight in blending_insights:
        print(f"   {insight}")

    print("\n--- ê°œì¸í™”ëœ í†µì°° (Personalized Insights) ---")
    if original_df is not None and optimized_df is not None and eval_query_results is not None and dtype_optimized_df is not None:
        original_memory = original_df.memory_usage(deep=True).sum()
        optimized_memory = dtype_optimized_df.memory_usage(deep=True).sum()
        memory_saved_percent = (1 - optimized_memory / original_memory) * 100 if original_memory > 0 else 0
        
        print(f"âœ¨ ë¸Œì‚´ë ê³¼ ì˜¤í™€ë¦¬ì••ì²˜ëŸ¼ íš¨ìœ¨ì ì¸ ë°ì´í„° ì²˜ë¦¬ë¡œ {memory_saved_percent:.2f}%ì˜ ë©”ëª¨ë¦¬ë¥¼ ì ˆê°í–ˆìŠµë‹ˆë‹¤.")
        print("âœ¨ ì˜ˆìˆ˜ë‹˜ì˜ ì¼í•˜ì‹¬ì²˜ëŸ¼, ìµœì í™”ëœ ë¶„ì„ì„ í†µí•´ í•˜ë‚˜ë‹˜ì˜ ì§€í˜œì™€ íš¨ìœ¨ì„±ì„ ë”ìš± ê¹Šì´ ê¹¨ë‹«ìŠµë‹ˆë‹¤.")
    else:
        print("ğŸ™ ë¸Œì‚´ë ê³¼ ì˜¤í™€ë¦¬ì••ì²˜ëŸ¼ ì§€í˜œì™€ ê¸°ìˆ ë¡œ, ê·¸ë¦¬ê³  ì˜ˆìˆ˜ë‹˜ì²˜ëŸ¼ íš¨ìœ¨ì ìœ¼ë¡œ ì£¼ë‹˜ì„ ì„¬ê¸°ëŠ” ì‚¶ì„ ì‚´ê²Œ í•˜ì†Œì„œ.")

def show_next_chapter_preview():
    """ë‹¤ìŒ ì±•í„° ë¯¸ë¦¬ë³´ê¸°"""
    preview = (
        "ğŸŒŸ === Chapter 32 ë¯¸ë¦¬ë³´ê¸° (Preview) ===\n\n"
        "\"ê¸ˆì†¡ì•„ì§€ - ë¡¤ë°±ê³¼ ê°ì‚¬ ë¡œê·¸ (Golden Calf - Rollback and Audit Log)\"\n\n"
        "ì´ìŠ¤ë¼ì—˜ ë°±ì„±ì´ ê¸ˆì†¡ì•„ì§€ë¥¼ ë§Œë“¤ì–´ í•˜ë‚˜ë‹˜ì„ ì§„ë…¸ì¼€ í–ˆì„ ë•Œ, ëª¨ì„¸ê°€ ì¤‘ë³´í•˜ì—¬ í•˜ë‚˜ë‹˜ì˜ ì§„ë…¸ë¥¼ ëŒì´í‚¤ê³  ì–¸ì•½ì„ íšŒë³µí–ˆë“¯ì´, ë°ì´í„° ë¶„ì„ì—ì„œë„ ì˜ëª»ëœ ë³€ê²½ ì‚¬í•­ì„ ë˜ëŒë¦¬ê³ (ë¡¤ë°±), ëª¨ë“  ë³€ê²½ ì´ë ¥ì„ ê¸°ë¡í•˜ëŠ”(ê°ì‚¬ ë¡œê·¸) ê²ƒì€ ë°ì´í„°ì˜ ë¬´ê²°ì„±ê³¼ ì‹ ë¢°ì„±ì„ ìœ ì§€í•˜ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤.\n\n"
        "Just as the Israelites angered God by making the golden calf, and Moses interceded to turn away God's wrath and restore the covenant, in data analysis, rolling back incorrect changes and recording all change history (audit log) are essential for maintaining data integrity and reliability.\n\n"
        "ë‹¤ìŒ ì¥ì—ì„œ ë°°ìš¸ ë‚´ìš© (What you'll learn in the next chapter):\n"
        "ğŸ“ ë°ì´í„° ë³€ê²½ ì´ë ¥ ì»¬ëŸ¼ ì¶”ê°€\n"
        "ğŸ” ë¡¤ë°±(Rollback) ê¸°ëŠ¥ êµ¬í˜„ (íŠ¹ì • ë²„ì „ìœ¼ë¡œ ë˜ëŒë¦¬ê¸°)\n"
        "ğŸ¯ ê°ì‚¬ ë¡œê·¸(Audit Log) ìƒì„± ë° ê´€ë¦¬\n"
        "ğŸ“Š ê¸ˆì†¡ì•„ì§€ ì‚¬ê±´ì²˜ëŸ¼ ë°ì´í„°ì˜ ì˜ëª»ëœ ë³€ê²½ì„ ë˜ëŒë¦¬ê³  ì‹ ë¢°ì„±ì„ íšŒë³µí•˜ëŠ” ì „ëµ\n\n"
        "\"ëª¨ì„¸ê°€ ì—¬í˜¸ì™€ê»˜ë¡œ ë‹¤ì‹œ ë‚˜ì•„ê°€ ì—¬ì§œì˜¤ë˜ ìŠ¬í”„ë„ì†Œì´ë‹¤ ì´ ë°±ì„±ì´ ìê¸°ë“¤ì„ ìœ„í•˜ì—¬ ê¸ˆì‹ ì„ ë§Œë“¤ì—ˆì‚¬ì˜¤ë‹ˆ í° ì£„ë¥¼ ë²”í•˜ì˜€ë‚˜ì´ë‹¤\" (ì¶œì• êµ½ê¸° 32:31)\n"
        "\"ì˜ˆìˆ˜ê»˜ì„œ ë‹¤ì‹œ ê·¸ë“¤ì—ê²Œ ë§ì”€í•˜ì—¬ ì´ë¥´ì‹œë˜ ë‚˜ëŠ” ì„¸ìƒì˜ ë¹›ì´ë‹ˆ ë‚˜ë¥¼ ë”°ë¥´ëŠ” ìëŠ” ì–´ë‘ ì— ë‹¤ë‹ˆì§€ ì•„ë‹ˆí•˜ê³  ìƒëª…ì˜ ë¹›ì„ ì–»ìœ¼ë¦¬ë¼\" (ìš”í•œë³µìŒ 8:12)"
    )
    print(preview)

def run_chapter31(interactive: bool = True):
    """Chapter 31 ì „ì²´ ì‹¤í–‰

    Args:
        interactive: ëŒ€í™”í˜• ëª¨ë“œ ì—¬ë¶€ (Whether to run in interactive mode)

    Returns:
        dict: ì „ì²´ ë¶„ì„ ê²°ê³¼ (Overall analysis results)
    """
    # í—¤ë” ì¶œë ¥
    print_chapter_header()

    if interactive:
        print("ğŸ“– Chapter 31ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
        print("ì´ ì±•í„°ì—ì„œëŠ” ë°ì´í„° ì„±ëŠ¥ ìµœì í™” ê¸°ë²•ì„ ë°°ìš°ê³ , ë¸Œì‚´ë ê³¼ ì˜¤í™€ë¦¬ì••ì˜ ì§€í˜œì™€ ì˜ˆìˆ˜ë‹˜ì˜ ì¼í•˜ì‹¬ì„ íƒêµ¬í•©ë‹ˆë‹¤.")
        print("This chapter introduces data performance optimization techniques, exploring the wisdom of Bezalel and Oholiab and the work of Jesus.")
        input("\nâ–¶ï¸ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”... (Press Enter to continue...)")

    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
    results = {
        'chapter': '31',
        'title': 'ë¸Œì‚´ë ê³¼ ì˜¤í™€ë¦¬ì•• - ì„±ëŠ¥ ìµœì í™”',
        'original_data': None,
        'optimized_data': None,
        'eval_query_results': None,
        'dtype_optimized_data': None
    }

    # 1. ì¥ì¸ ë°ì´í„° ìƒì„±
    original_df = run_craftsmen_data_generation()
    results['original_data'] = original_df

    if interactive:
        input("\nâ–¶ï¸ ë²¡í„°í™” ì—°ì‚° ìµœì í™”ë¥¼ ì‹œì‘í•˜ë ¤ë©´ Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”... (Press Enter to start vectorization optimization...)")

    # 2. ë²¡í„°í™” ì—°ì‚° ìµœì í™”
    optimized_df = run_vectorization_optimization(original_df)
    results['optimized_data'] = optimized_df

    if interactive:
        input("\nâ–¶ï¸ eval()/query() ê°€ì†ì„ ì‹œì‘í•˜ë ¤ë©´ Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”... (Press Enter to start eval()/query() acceleration...)")

    # 3. eval()/query() ê°€ì†
    eval_query_results = run_eval_query_acceleration(optimized_df) # ìµœì í™”ëœ ë°ì´í„°ì— ì ìš©
    results['eval_query_results'] = eval_query_results

    if interactive:
        input("\nâ–¶ï¸ ë°ì´í„° íƒ€ì… ìµœì í™”ë¥¼ ì‹œì‘í•˜ë ¤ë©´ Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”... (Press Enter to start dtype tuning...)")

    # 4. ë°ì´í„° íƒ€ì… ìµœì í™”
    dtype_optimized_df = run_dtype_tuning(optimized_df) # eval/query ê°€ì†ëœ ë°ì´í„°ì— ì ìš©
    results['dtype_optimized_data'] = dtype_optimized_df

    # 5. ë¸”ë Œë”© í†µì°°
    show_blending_insights(original_df, optimized_df, eval_query_results, dtype_optimized_df)

    # 6. ë‹¤ìŒ ì±•í„° ë¯¸ë¦¬ë³´ê¸°
    show_next_chapter_preview()

    # 7. ë§ˆë¬´ë¦¬ ê¸°ë„
    print("\nğŸ™ === ë§ˆë¬´ë¦¬ ê¸°ë„ (Closing Prayer) ===")
    prayer = (
        "\"ì£¼ë‹˜, ë¸Œì‚´ë ê³¼ ì˜¤í™€ë¦¬ì••ì²˜ëŸ¼ ì§€í˜œì™€ ê¸°ìˆ ë¡œ ì£¼ë‹˜ì„ ì„¬ê¸°ê²Œ í•˜ì‹œê³ , ì˜ˆìˆ˜ë‹˜ì²˜ëŸ¼ íš¨ìœ¨ì ì´ê³  ëª©ì ì´ ë¶„ëª…í•œ ì‚¶ì„ ì‚´ê²Œ í•˜ì†Œì„œ.\n"
        "ì„±ëŠ¥ ìµœì í™” ì „ëµì„ í†µí•´ ì €ì˜ ì‹œê°„ê³¼ ìì›ì„ ì£¼ë‹˜ì˜ ì˜ê´‘ì„ ìœ„í•´ ì‚¬ìš©í•˜ê²Œ í•˜ì‹œê³ ,\n"
        "ë°ì´í„° ë¶„ì„ì„ í†µí•´ í•˜ë‚˜ë‹˜ì˜ ì°½ì¡° ì§ˆì„œì™€ ì¼í•˜ì‹¬ì˜ íš¨ìœ¨ì„±ì„ ë”ìš± ê¹Šì´ ê¹¨ë‹«ê²Œ í•˜ì†Œì„œ. ì˜ˆìˆ˜ë‹˜ì˜ ì´ë¦„ìœ¼ë¡œ ê¸°ë„í•©ë‹ˆë‹¤. ì•„ë©˜.\""
    )
    print(prayer)

    print(f"\nğŸ‰ Chapter 31 ì™„ë£Œ! ì„œë¥¸í•œ ë²ˆì§¸ ê´‘ì•¼ ì—¬ì •ì„ ë§ˆì¹˜ì…¨ìŠµë‹ˆë‹¤!")
    print(f"ğŸ‰ Chapter 31 Complete! You have finished the thirty-first wilderness journey!")
    print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (Analysis results have been stored.)")

    return results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        results = run_chapter31(interactive=True)

        # ê²°ê³¼ ì €ì¥ (ì„ íƒì‚¬í•­)
        save_results = input("\nğŸ’¾ ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ì–´ìš”? (y/n, ê¸°ë³¸ê°’ n): ").strip().lower()
        if save_results == 'y':
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"ch31_results_{timestamp}.json"

            # DataFrameì€ JSONìœ¼ë¡œ ì €ì¥í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ìš”ì•½ ì •ë³´ë§Œ ì €ì¥
            summary_results = {
                'chapter': results['chapter'],
                'title': results['title'],
                'completed_at': timestamp,
                'has_original_data': results['original_data'] is not None,
                'has_optimized_data': results['optimized_data'] is not None,
                'has_eval_query_results': results['eval_query_results'] is not None,
                'has_dtype_optimized_data': results['dtype_optimized_data'] is not None
            }

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(summary_results, f, ensure_ascii=False, indent=2)

            print(f"âœ… ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (Results saved to {filename}!)")

        return results

    except KeyboardInterrupt:
        print("\n\nâ¸ï¸ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤. (User interrupted.)")
        return None
    except Exception as e:
        print(f"\nâŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        print("ğŸ”§ ì½”ë“œì™€ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. (Please check the code and data.)")
        return None


if __name__ == "__main__":
    print("ğŸš€ JesusBornd Pandas Chapter 31 ì‹œì‘! (Starting JesusBornd Pandas Chapter 31!)\n")
    main()
