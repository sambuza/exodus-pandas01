
'''
Chapter 35 í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
ìì› ë´‰í—Œ - IO í™•ì¥

"ì´ìŠ¤ë¼ì—˜ ìì†ì´ ì—¬í˜¸ì™€ê»˜ ë“œë¦¬ëŠ” ì˜ˆë¬¼ì€ ì´ëŸ¬í•˜ë‹ˆ ê³§ ê¸ˆê³¼ ì€ê³¼ ë†‹ê³¼" (ì¶œì• êµ½ê¸° 35:5)
"ì—¬ê¸° í•œ ì•„ì´ê°€ ìˆì–´ ë³´ë¦¬ë–¡ ë‹¤ì„¯ ê°œì™€ ë¬¼ê³ ê¸° ë‘ ë§ˆë¦¬ë¥¼ ê°€ì¡Œë‚˜ì´ë‹¤ ê·¸ëŸ¬ë‚˜ ì´ê²ƒì´ ì´ ë§ì€ ì‚¬ëŒì—ê²Œ ì–¼ë§ˆë‚˜ ë˜ê² ì‚¬ì˜µë‚˜ì´ê¹Œ" (ìš”í•œë³µìŒ 6:9)
'''

import sys
from pathlib import Path
import json
from datetime import datetime
import pandas as pd
import numpy as np
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT))

# ì ˆëŒ€ ì„í¬íŠ¸ ì‚¬ìš©
from chapters.ch35.offering_data import OfferingDataGenerator
from chapters.ch35.csv_io_handler import CsvIOHandler
from chapters.ch35.parquet_io_handler import ParquetIOHandler
from chapters.ch35.excel_io_handler import ExcelIOHandler

def print_chapter_header():
    '''ì±•í„° í—¤ë” ì¶œë ¥'''
    header = (
        "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n"
        "â•‘                    JesusBornd Pandas Edition                         â•‘\n"
        "â•‘                                                                      â•‘\n"
        "â•‘             Chapter 35: ìì› ë´‰í—Œ - IO í™•ì¥                          â•‘\n"
        "â•‘                                                                      â•‘\n"
        "    \"ì´ìŠ¤ë¼ì—˜ ìì†ì´ ì—¬í˜¸ì™€ê»˜ ë“œë¦¬ëŠ” ì˜ˆë¬¼ì€ ì´ëŸ¬í•˜ë‹ˆ ê³§ ê¸ˆê³¼ ì€ê³¼ ë†‹ê³¼\" (ì¶œì• êµ½ê¸° 35:5)\n"
        "    \"ì—¬ê¸° í•œ ì•„ì´ê°€ ìˆì–´ ë³´ë¦¬ë–¡ ë‹¤ì„¯ ê°œì™€ ë¬¼ê³ ê¸° ë‘ ë§ˆë¦¬ë¥¼ ê°€ì¡Œë‚˜ì´ë‹¤ ê·¸ëŸ¬ë‚˜ ì´ê²ƒì´ ì´ ë§ì€ ì‚¬ëŒì—ê²Œ ì–¼ë§ˆë‚˜ ë˜ê² ì‚¬ì˜µë‚˜ì´ê¹Œ\" (ìš”í•œë³µìŒ 6:9)\n"
        "â•‘                                                                      â•‘\n"
        "â•‘      ì¶œì• êµ½ê¸° 35ì¥: ìì› ë´‰í—Œ                                        â•‘\n"
        "â•‘      ìš”í•œë³µìŒ 6:9: ì˜¤ë³‘ì´ì–´                                          â•‘\n"
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )
    print(header)

def run_offering_data_generation():
    '''ìì› ë´‰í—Œ ë°ì´í„° ìƒì„± ì„¹ì…˜ ì‹¤í–‰'''
    print("\nğŸ === ìì› ë´‰í—Œ ë°ì´í„° ìƒì„± ===")
    print("ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì½ê³  ì“°ëŠ” ë° ì‚¬ìš©ë  ìì› ë´‰í—Œ ê´€ë ¨ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    print("Generates offering-related data for efficient reading and writing of various data formats.")

    try:
        generator = OfferingDataGenerator()
        data = generator.generate_offering_data()
        print("\nâœ… ìì› ë´‰í—Œ ë°ì´í„° ìƒì„± ì™„ë£Œ:")
        print(data.head())
        return data
    except Exception as e:
        print(f"âŒ ìì› ë´‰í—Œ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def run_csv_io_operations(df):
    '''CSV íŒŒì¼ ì…ì¶œë ¥ ì„¹ì…˜ ì‹¤í–‰'''
    print("\nğŸ“„ === CSV íŒŒì¼ ì…ì¶œë ¥ ===")
    print("`to_csv()`ì™€ `read_csv()`ë¥¼ ì‚¬ìš©í•˜ì—¬ CSV íŒŒì¼ë¡œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
    print("Saves and loads data to/from CSV files using `to_csv()` and `read_csv()`.")

    if df is None:
        print("âš ï¸ ë°ì´í„°ê°€ ì—†ì–´ CSV íŒŒì¼ ì…ì¶œë ¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None

    try:
        handler = CsvIOHandler(df)
        csv_filename = "ch35_offering_data.csv"
        saved_path = handler.save_data(csv_filename)
        loaded_df = handler.load_data(csv_filename)
        print("\nâœ… CSV íŒŒì¼ ì…ì¶œë ¥ ì™„ë£Œ (ë¶ˆëŸ¬ì˜¨ ë°ì´í„° ì¼ë¶€):")
        print(loaded_df.head())
        
        if os.path.exists(saved_path): os.remove(saved_path)
        return loaded_df
    except Exception as e:
        print(f"âŒ CSV íŒŒì¼ ì…ì¶œë ¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def run_parquet_io_operations(df):
    '''Parquet íŒŒì¼ ì…ì¶œë ¥ ì„¹ì…˜ ì‹¤í–‰'''
    print("\nğŸ“¦ === Parquet íŒŒì¼ ì…ì¶œë ¥ ===")
    print("`to_parquet()`ì™€ `read_parquet()`ë¥¼ ì‚¬ìš©í•˜ì—¬ Parquet íŒŒì¼ë¡œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
    print("Saves and loads data to/from Parquet files using `to_parquet()` and `read_parquet()`.")

    if df is None:
        print("âš ï¸ ë°ì´í„°ê°€ ì—†ì–´ Parquet íŒŒì¼ ì…ì¶œë ¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None

    try:
        handler = ParquetIOHandler(df)
        parquet_filename = "ch35_offering_data.parquet"
        saved_path = handler.save_data(parquet_filename)
        loaded_df = handler.load_data(parquet_filename)
        print("\nâœ… Parquet íŒŒì¼ ì…ì¶œë ¥ ì™„ë£Œ (ë¶ˆëŸ¬ì˜¨ ë°ì´í„° ì¼ë¶€):")
        print(loaded_df.head())
        
        if os.path.exists(saved_path): os.remove(saved_path)
        return loaded_df
    except Exception as e:
        print(f"âŒ Parquet íŒŒì¼ ì…ì¶œë ¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def run_excel_io_operations(df):
    '''Excel íŒŒì¼ ì…ì¶œë ¥ ì„¹ì…˜ ì‹¤í–‰'''
    print("\nğŸ“Š === Excel íŒŒì¼ ì…ì¶œë ¥ ===")
    print("`to_excel()`ì™€ `read_excel()`ë¥¼ ì‚¬ìš©í•˜ì—¬ Excel íŒŒì¼ë¡œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
    print("Saves and loads data to/from Excel files using `to_excel()` and `read_excel()`.")

    if df is None:
        print("âš ï¸ ë°ì´í„°ê°€ ì—†ì–´ Excel íŒŒì¼ ì…ì¶œë ¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None

    try:
        handler = ExcelIOHandler(df)
        excel_filename = "ch35_offering_data.xlsx"
        saved_path = handler.save_data(excel_filename)
        loaded_df = handler.load_data(excel_filename)
        print("\nâœ… Excel íŒŒì¼ ì…ì¶œë ¥ ì™„ë£Œ (ë¶ˆëŸ¬ì˜¨ ë°ì´í„° ì¼ë¶€):")
        print(loaded_df.head())
        
        if os.path.exists(saved_path): os.remove(saved_path)
        return loaded_df
    except Exception as e:
        print(f"âŒ Excel íŒŒì¼ ì…ì¶œë ¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def show_blending_insights(original_df, csv_df, parquet_df, excel_df):
    '''ë¸”ë Œë”© ëª¨ë“œ í†µí•© í†µì°° ì¶œë ¥'''
    print("\nğŸ¨ === ë¸”ë Œë”© ëª¨ë“œ: ì¶œì• êµ½ Ã— ìš”í•œë³µìŒì˜ í†µí•© í†µì°° ===")
    print("Blending Mode: Integrated Insights from Exodus x John")

    blending_insights = [
        "ğŸ“Š IO í™•ì¥ = ë°ì´í„°ì˜ í™œìš©ë„ ê·¹ëŒ€í™”ì™€ ë¶„ì„ íŒŒì´í”„ë¼ì¸ í™•ì¥",
        "ğŸ ìì› ë´‰í—Œ = ë‹¤ì–‘í•œ ìì›ì˜ íš¨ìœ¨ì  í™œìš©ê³¼ í•˜ë‚˜ë‹˜ì˜ ëœ»ì„ ì´ë£¨ëŠ” í”„ë¡œì íŠ¸",
        "ğŸğŸŸ ì˜¤ë³‘ì´ì–´ = ì‘ì€ ìì›ì˜ ë†€ë¼ìš´ í™•ì¥ê³¼ í’ì„±í•¨",
        "ğŸ’¡ ë°ì´í„° ì ‘ê·¼ì„± = ì˜ì  ì„±ì¥ê³¼ ë¶„ì„ íš¨ìœ¨ì„±ì˜ ì¡°í™”"
    ]

    print("\nğŸ’ í•µì‹¬ ë°œê²¬ë“¤ (Key Discoveries):\n")
    for insight in blending_insights:
        print(f"   {insight}")

    print("\n--- ê°œì¸í™”ëœ í†µì°° (Personalized Insights) ---")
    if original_df is not None and csv_df is not None and parquet_df is not None and excel_df is not None:
        print("âœ¨ ìì› ë´‰í—Œì²˜ëŸ¼ ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë‹¤ë£¨ì–´ ë°ì´í„°ì˜ í™œìš©ë„ë¥¼ ë†’ì˜€ìŠµë‹ˆë‹¤.")
        print("âœ¨ ì˜¤ë³‘ì´ì–´ì²˜ëŸ¼ ì‘ì€ ë°ì´í„°ë¼ë„ íš¨ìœ¨ì ìœ¼ë¡œ ì½ê³  ì¨ì„œ ë¶„ì„ íŒŒì´í”„ë¼ì¸ì„ í™•ì¥í•©ë‹ˆë‹¤.")
    else:
        print("ğŸ™ ìì› ë´‰í—Œì²˜ëŸ¼ ë‚˜ì˜ ëª¨ë“  ê²ƒì„ ì£¼ë‹˜ê»˜ ë“œë¦¬ê³ , ì˜¤ë³‘ì´ì–´ì²˜ëŸ¼ ì£¼ë‹˜ ì•ˆì—ì„œ ë†€ëê²Œ í™•ì¥ë˜ê²Œ í•˜ì†Œì„œ.")

def show_next_chapter_preview():
    '''ë‹¤ìŒ ì±•í„° ë¯¸ë¦¬ë³´ê¸°'''
    preview = (
        "ğŸŒŸ === Chapter 36 ë¯¸ë¦¬ë³´ê¸° (Preview) ===\n\n"
        "\"ì¥ì¸ì˜ ì† - ê²°í•©Â·ì¬êµ¬ì„± ì‹¬í™” (Craftsman's Hand - Advanced Join and Reshaping)\"\n\n"
        "ë¸Œì‚´ë ê³¼ ì˜¤í™€ë¦¬ì••ì´ ì„±ë§‰ ê±´ì¶•ì— í•„ìš”í•œ ëª¨ë“  ê¸°ìˆ ê³¼ ì§€í˜œë¥¼ ë¶€ì—¬ë°›ì•„ ìµœê³ ì˜ ì‘í’ˆì„ ë§Œë“¤ì—ˆë“¯ì´, ë°ì´í„° ë¶„ì„ì—ì„œë„ ì—¬ëŸ¬ ë°ì´í„°ì…‹ì„ ë³µì¡í•˜ê²Œ ê²°í•©í•˜ê³  ì¬êµ¬ì„±í•˜ëŠ” ê²ƒì€ ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ íŒ¨í„´ê³¼ ì˜ë¯¸ë¥¼ ë°œê²¬í•˜ê³  ê¹Šì´ ìˆëŠ” í†µì°°ì„ ì–»ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤.\n\n"
        "Just as Bezalel and Oholiab were endowed with all the skills and wisdom needed to build the tabernacle, creating the finest work, in data analysis, complex joining and reshaping of multiple datasets are essential for discovering hidden patterns and meanings and gaining deep insights.\n\n"
        "ë‹¤ìŒ ì¥ì—ì„œ ë°°ìš¸ ë‚´ìš© (What you'll learn in the next chapter):\n"
        "ğŸ“ `wide_to_long()`: ë„“ì€ í˜•ì‹ ë°ì´í„°ë¥¼ ê¸´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n"
        "ğŸ” ë‹¤ë‹¨ í”¼ë²—(Multi-level Pivot) ë° ì—­í”¼ë²—(Unpivot)\n"
        "ğŸ¯ ê³ ê¸‰ ì¡°ì¸(Join) ì „ëµ (ì˜ˆ: Fuzzy Join ê°œë…)\n"
        "ğŸ“Š ì¥ì¸ì˜ ì†ì²˜ëŸ¼ ì •êµí•˜ê³  ë³µì¡í•œ ë°ì´í„° ê²°í•© ë° ì¬êµ¬ì„±ì„ í†µí•´ í•˜ë‚˜ë‹˜ì˜ ì§€í˜œë¥¼ íƒêµ¬\n\n"
        "\"ëª¨ì„¸ê°€ ê·¸ ì¥ì¸ì˜ ë§ì„ ë“£ê³  ê·¸ ë§ëŒ€ë¡œ í•˜ì—¬\" (ì¶œì• êµ½ê¸° 36:1-7)\n"
        "\"ì˜ˆìˆ˜ê»˜ì„œ ëŒ€ë‹µí•˜ì—¬ ì´ë¥´ì‹œë˜ ë„ˆí¬ê°€ ì´ ì„±ì „ì„ í—ë¼ ë‚´ê°€ ì‚¬í˜ ë™ì•ˆì— ì¼ìœ¼í‚¤ë¦¬ë¼ í•˜ì‹œë‹ˆë¼\" (ìš”í•œë³µìŒ 2:19)"
    )
    print(preview)

def run_chapter35(interactive: bool = True):
    '''Chapter 35 ì „ì²´ ì‹¤í–‰'''
    # í—¤ë” ì¶œë ¥
    print_chapter_header()

    if interactive:
        print("ğŸ“– Chapter 35ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
        print("ì´ ì±•í„°ì—ì„œëŠ” ë‹¤ì–‘í•œ í˜•ì‹ì˜ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì½ê³  ì“°ëŠ” IO í™•ì¥ ê¸°ë²•ì„ ë°°ìš°ê³ , ìì› ë´‰í—Œê³¼ ì˜¤ë³‘ì´ì–´ ì‚¬ê±´ì„ íƒêµ¬í•©ë‹ˆë‹¤.")
        print("This chapter introduces IO extension techniques for efficiently reading and writing various data formats, exploring voluntary offerings and the feeding of the five thousand.")
        input("\nâ–¶ï¸ ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”... (Press Enter to continue...)")

    # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
    results = {
        'chapter': '35',
        'title': 'ìì› ë´‰í—Œ - IO í™•ì¥',
        'original_data': None,
        'csv_data': None,
        'parquet_data': None,
        'excel_data': None
    }

    # 1. ìì› ë´‰í—Œ ë°ì´í„° ìƒì„±
    original_df = run_offering_data_generation()
    results['original_data'] = original_df

    if interactive:
        input("\nâ–¶ï¸ CSV íŒŒì¼ ì…ì¶œë ¥ì„ ì‹œì‘í•˜ë ¤ë©´ Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”... (Press Enter to start CSV IO operations...)")

    # 2. CSV íŒŒì¼ ì…ì¶œë ¥
    csv_df = run_csv_io_operations(original_df)
    results['csv_data'] = csv_df

    if interactive:
        input("\nâ–¶ï¸ Parquet íŒŒì¼ ì…ì¶œë ¥ì„ ì‹œì‘í•˜ë ¤ë©´ Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”... (Press Enter to start Parquet IO operations...)")

    # 3. Parquet íŒŒì¼ ì…ì¶œë ¥
    parquet_df = run_parquet_io_operations(original_df) # ì›ë³¸ ë°ì´í„°ì— ì ìš©
    results['parquet_data'] = parquet_df

    if interactive:
        input("\nâ–¶ï¸ Excel íŒŒì¼ ì…ì¶œë ¥ì„ ì‹œì‘í•˜ë ¤ë©´ Enterë¥¼ ëˆŒëŸ¬ì£¼ì„¸ìš”... (Press Enter to start Excel IO operations...)")

    # 4. Excel íŒŒì¼ ì…ì¶œë ¥
    excel_df = run_excel_io_operations(original_df) # ì›ë³¸ ë°ì´í„°ì— ì ìš©
    results['excel_data'] = excel_df

    # 5. ë¸”ë Œë”© í†µì°°
    show_blending_insights(original_df, csv_df, parquet_df, excel_df)

    # 6. ë‹¤ìŒ ì±•í„° ë¯¸ë¦¬ë³´ê¸°
    show_next_chapter_preview()

    # 7. ë§ˆë¬´ë¦¬ ê¸°ë„
    print("\nğŸ™ === ë§ˆë¬´ë¦¬ ê¸°ë„ (Closing Prayer) ===")
    prayer = (
        "\"ì£¼ë‹˜, ìì› ë´‰í—Œì²˜ëŸ¼ ì €ì˜ ëª¨ë“  ìì›ì„ ì£¼ë‹˜ê»˜ ë“œë¦¬ê³ , ì˜¤ë³‘ì´ì–´ì²˜ëŸ¼ ì£¼ë‹˜ ì•ˆì—ì„œ ë†€ëê²Œ í™•ì¥ë˜ê²Œ í•˜ì†Œì„œ.\n"
        "ë°ì´í„° IO í™•ì¥ ì „ëµì„ í†µí•´ ì €ì˜ ì˜ì  ê¸°ë¡ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³ , ì£¼ë‹˜ì˜ ëœ»ì„ ì˜¨ì „íˆ ì´í•´í•˜ê²Œ í•˜ì†Œì„œ.\n"
        "ë°ì´í„° ë¶„ì„ì„ í†µí•´ í•˜ë‚˜ë‹˜ì˜ ì§€í˜œë¡œìš´ ìì› ê´€ë¦¬ ì›ë¦¬ë¥¼ ë”ìš± ê¹Šì´ ê¹¨ë‹«ê²Œ í•˜ì†Œì„œ. ì˜ˆìˆ˜ë‹˜ì˜ ì´ë¦„ìœ¼ë¡œ ê¸°ë„í•©ë‹ˆë‹¤. ì•„ë©˜.\""
    )
    print(prayer)

    print(f"\nğŸ‰ Chapter 35 ì™„ë£Œ! ì„œë¥¸ë‹¤ì„¯ ë²ˆì§¸ ê´‘ì•¼ ì—¬ì •ì„ ë§ˆì¹˜ì…¨ìŠµë‹ˆë‹¤!")
    print(f"ğŸ‰ Chapter 35 Complete! You have finished the thirty-fifth wilderness journey!")
    print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (Analysis results have been stored.)")

    return results

def main():
    '''ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜'''
    try:
        results = run_chapter35(interactive=True)

        # ê²°ê³¼ ì €ì¥ (ì„ íƒì‚¬í•­)
        save_results = input("\nğŸ’¾ ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ì–´ìš”? (y/n, ê¸°ë³¸ê°’ n): ").strip().lower()
        if save_results == 'y':
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"ch35_results_{timestamp}.json"

            # DataFrameì€ JSONìœ¼ë¡œ ì €ì¥í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ìš”ì•½ ì •ë³´ë§Œ ì €ì¥
            summary_results = {
                'chapter': results['chapter'],
                'title': results['title'],
                'completed_at': timestamp,
                'has_original_data': results['original_data'] is not None,
                'has_csv_data': results['csv_data'] is not None,
                'has_parquet_data': results['parquet_data'] is not None,
                'has_excel_data': results['excel_data'] is not None
            }

            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(summary_results, f, ensure_ascii=False, indent=2)

            print(f"âœ… ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (Results saved to {filename}!)")

        return results

    except KeyboardInterrupt:
        print("\n\nâ¸ï¸ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤. (User interrupted.)")
        return None
    except Exception as e:
        print(f"\nâŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        print("ğŸ”§ ì½”ë“œì™€ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”. (Please check the code and data.)")
        return None


if __name__ == "__main__":
    print("ğŸš€ JesusBornd Pandas Chapter 35 ì‹œì‘! (Starting JesusBornd Pandas Chapter 35!)\n")
    main()
